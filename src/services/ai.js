const { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } = require("@google/generative-ai");
const config = require('../config');
const prompts = require('../core/prompts');
const axios = require('axios');
const OpenAI = require('openai');
const { tavily } = require('@tavily/core'); // –ö–ª–∏–µ–Ω—Ç Tavily

class AiService {
  constructor() {
    // 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ (OpenRouter / Mistral / DeepSeek)
    this.openai = config.aiKey ? new OpenAI({
        baseURL: config.aiBaseUrl,
        apiKey: config.aiKey,
        defaultHeaders: {
          "HTTP-Referer": "https://github.com/Veta-one/sych-bot",
          "X-Title": "Sych Bot"
        }
    }) : null;

    // 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Tavily
    this.tavilyClient = config.tavilyKey ? tavily({ apiKey: config.tavilyKey }) : null;

    // 3. Google Native (Fallback)
    this.keyIndex = 0; 
    this.keys = config.geminiKeys;
    this.usingFallback = false; 
    this.bot = null; 

    // === –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
    this.stats = { 
        smart: 0, 
        logic: 0, 
        search: 0,
        google: this.keys.map(() => ({ count: 0, status: true }))
    };
    this.lastResetDate = new Date().getDate(); 
    
    if (this.keys.length === 0) console.warn("WARNING: –ù–µ—Ç –∫–ª—é—á–µ–π Gemini –≤ .env! Fallback –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç.");
    this.initNativeModel();
  }

  setBot(botInstance) {
    this.bot = botInstance;
  }

  notifyAdmin(message) {
    if (this.bot && config.adminId) {
        this.bot.sendMessage(config.adminId, message, { parse_mode: 'Markdown' }).catch(() => {});
    }
  }

  // –°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ –ø–æ–ª–Ω–æ—á—å
  resetStatsIfNeeded() {
    const today = new Date().getDate();
    if (today !== this.lastResetDate) {
        this.stats = { smart: 0, logic: 0, search: 0, google: this.keys.map(() => ({ count: 0, status: true })) };
        this.lastResetDate = today;
        
        if (this.usingFallback) {
            this.usingFallback = false;
            this.keyIndex = 0;
            this.initNativeModel();
            this.notifyAdmin("üåô **–ù–æ–≤—ã–π –¥–µ–Ω—å!**\n–õ–∏–º–∏—Ç—ã —Å–±—Ä–æ—à–µ–Ω—ã. –í–æ–∑–≤—Ä–∞—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∂–∏–º.");
        }
    }
  }

  getStatsReport() {
  this.resetStatsIfNeeded();
  const mode = this.usingFallback ? "‚ö†Ô∏è FALLBACK (Google Native)" : "‚ö° API MODE";

  const apiText = `üåê **API (${config.aiBaseUrl}):**\n   Smart: ${this.stats.smart}\n   Logic: ${this.stats.logic}\n   Search: ${this.stats.search}`;
  const googleRows = this.stats.google.map((s, i) => `   üîë${i + 1}: ${s.status ? "üü¢" : "üî¥"} ${s.count}`).join('\n');

  return `–†–µ–∂–∏–º: ${mode}\n\n${apiText}\n\nüíé **Google Native:**\n${googleRows}`;
  }

  initNativeModel() {
    if (this.keys.length === 0) return;
    const currentKey = this.keys[this.keyIndex];
    const genAI = new GoogleGenerativeAI(currentKey);
    
    const safetySettings = [
        { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
    ];

    // –ò—Å–ø–æ–ª—å–∑—É–µ–º Fallback –º–æ–¥–µ–ª—å –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é Flash (–æ–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –Ω–∞—Ç–∏–≤–µ)
    const modelName = this.usingFallback ? config.fallbackModelName : config.googleNativeModel;
    console.log(`[AI INIT] Native Key #${this.keyIndex + 1} | Model: ${modelName}`);

    this.nativeModel = genAI.getGenerativeModel({ 
        model: modelName,
        systemInstruction: prompts.system(),
        safetySettings: safetySettings,
        // –í–∫–ª—é—á–∞–µ–º –Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ Google (Tools)
        tools: [{ googleSearch: {} }] 
    });
  }

  rotateNativeKey() {
    if (this.stats.google[this.keyIndex]) this.stats.google[this.keyIndex].status = false;
    
    console.log(`[AI WARNING] Native Key #${this.keyIndex + 1} –∏—Å—á–µ—Ä–ø–∞–Ω.`);
    this.keyIndex++;

    if (this.keyIndex >= this.keys.length) {
        this.keyIndex = 0;
        console.error("‚ò†Ô∏è –í—Å–µ –Ω–∞—Ç–∏–≤–Ω—ã–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã.");
        this.notifyAdmin("‚ö†Ô∏è **–í–Ω–∏–º–∞–Ω–∏–µ!** –í—Å–µ Google –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã.");
    }
    this.initNativeModel();
  }

  async executeNativeWithRetry(apiCallFn) {
    const maxAttempts = this.keys.length * 2; 

    for (let attempt = 0; attempt < maxAttempts; attempt++) {
        try {
            if (this.stats.google[this.keyIndex]) this.stats.google[this.keyIndex].count++;
            return await apiCallFn();
        } catch (error) {
            const isQuotaError = error.message.includes('429') || error.message.includes('Quota') || error.message.includes('403');
            if (isQuotaError) {
                this.rotateNativeKey(); 
                continue;
            } else {
                throw error;
            }
        }
    }
    throw new Error("–í—Å–µ –∫–ª—é—á–∏ Google Native –∏—Å—á–µ—Ä–ø–∞–Ω—ã!");
  }

  getCurrentTime() {
    const time = new Date().toLocaleString("ru-RU", {
      timeZone: "Asia/Yekaterinburg",
      weekday: 'short', // –°–æ–∫—Ä–∞—Ç–∏–º –¥–æ –ü—Ç, –ü–Ω (—ç–∫–æ–Ω–æ–º–∏–º —Ç–æ–∫–µ–Ω—ã)
      year: 'numeric',
      month: 'numeric',
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit'
    });
    // –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –±–∞–∑—É –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤
    return `${time} (UTC+5)`;
  }

// === –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ü–û–ò–°–ö ===
async performSearch(query) {
  this.resetStatsIfNeeded();

  // 1. TAVILY
  if (config.searchProvider === 'tavily' && this.tavilyClient) {
      try {
          console.log(`[SEARCH] Tavily –∏—â–µ—Ç: ${query}`);
          const response = await this.tavilyClient.search(query, {
              search_depth: "advanced",
              max_results: 3,
              include_answer: true 
          });
          this.stats.search++;
          
          let resultText = "";
          if (response.answer) resultText += `–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç Tavily: ${response.answer}\n\n`;
          response.results.forEach((res, i) => {
              resultText += `[${i+1}] ${res.title} (${res.url}):\n${res.content}\n\n`;
          });
          return resultText;
      } catch (e) {
          console.error(`[TAVILY FAIL] ${e.message}`);
          return null;
      }
  }

  // 2. PERPLEXITY
  if (config.searchProvider === 'perplexity' && this.openai) {
      try {
          console.log(`[SEARCH] Perplexity –∏—â–µ—Ç: ${query}`);
          const completion = await this.openai.chat.completions.create({
              model: config.perplexityModel,
              messages: [
                  { role: "system", content: `Date: ${this.getCurrentTime()}. Search engine mode. Provide facts with URLs.` },
                  { role: "user", content: query }
              ],
              temperature: 0.1
          });
          this.stats.search++;
          return completion.choices[0].message.content;
      } catch (e) {
          console.error(`[PERPLEXITY FAIL] ${e.message}`);
          return null;
      }
  }
  
  return null;
}
  
// === –û–°–ù–û–í–ù–û–ô –û–¢–í–ï–¢ ===
async getResponse(history, currentMessage, imageBuffer = null, mimeType = "image/jpeg", userInstruction = "", userProfile = null, isSpontaneous = false, chatProfile = null) {
  this.resetStatsIfNeeded();
  console.log(`[DEBUG AI] getResponse –≤—ã–∑–≤–∞–Ω.`);

  // 1. AI –û–ü–†–ï–î–ï–õ–Ø–ï–¢ –ù–£–ñ–ï–ù –õ–ò –ü–û–ò–°–ö
  const recentHistory = history.slice(-5).map(m => `${m.role}: ${m.text}`).join('\n');
  const searchDecision = await this.checkSearchNeeded(
      currentMessage.text,
      recentHistory,
      chatProfile?.topic || null
  );

  let searchResultText = "";

  if (searchDecision.needsSearch && searchDecision.searchQuery) {
      // 2. –ü–û–ò–°–ö –ß–ï–†–ï–ó TAVILY / PERPLEXITY
      if (config.searchProvider !== 'google') {
          searchResultText = await this.performSearch(searchDecision.searchQuery);
      }

      // 3. FALLBACK –ù–ê GOOGLE NATIVE SEARCH
      // –ï—Å–ª–∏ Tavily/Perplexity –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä = google
      if (!searchResultText && this.keys.length > 0) {
          console.log(`[ROUTER] –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ Google Native Search.`);
          return this.generateViaNative(history, currentMessage, imageBuffer, mimeType, userInstruction, userProfile, isSpontaneous, chatProfile);
      }
  }

  // 2. –°–ë–û–†–ö–ê –ü–†–û–ú–ü–¢–ê
  const relevantHistory = history.slice(-20); 
  const contextStr = relevantHistory.map(m => `${m.role}: ${m.text}`).join('\n');
  let personalInfo = "";
  let replyContext = "";

  if (currentMessage.replyText) replyContext = `!!! –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨ –û–¢–í–ï–¢–ò–õ –ù–ê –°–û–û–ë–©–ï–ù–ò–ï:\n"${currentMessage.replyText}"`;
  if (userInstruction) personalInfo += `\n!!! –°–ü–ï–¶-–ò–ù–°–¢–†–£–ö–¶–ò–Ø !!!\n${userInstruction}\n`;
  
  if (searchResultText) {
      personalInfo += `\n!!! –î–ê–ù–ù–´–ï –ò–ó –ü–û–ò–°–ö–ê (${config.searchProvider.toUpperCase()}) !!!\n${searchResultText}\n–ò–ù–°–¢–†–£–ö–¶–ò–Ø: –û—Ç–≤–µ—Ç—å, –∏—Å–ø–æ–ª—å–∑—É—è —ç—Ç–∏ —Ñ–∞–∫—Ç—ã. –£–ö–ê–ñ–ò –°–°–´–õ–ö–ò.\n`;
  }

  if (userProfile) {
      const score = userProfile.relationship || 50;
      let relationText = score <= 20 ? "–°–¢–ê–¢–£–°: –í–†–ê–ì." : score >= 80 ? "–°–¢–ê–¢–£–°: –ë–†–ê–¢–ê–ù." : "–°–¢–ê–¢–£–°: –ù–ï–ô–¢–†–ê–õ–¨–ù–û.";
      personalInfo += `\n--- –î–û–°–¨–ï ---\n–§–∞–∫—Ç—ã: ${userProfile.facts || "–ù–µ—Ç"}\n`;
      if (userProfile.location) personalInfo += `üìç –õ–æ–∫–∞—Ü–∏—è: ${userProfile.location}\n`;
      personalInfo += `${relationText}\n-----------------\n`;
  }

  const fullPromptText = prompts.mainChat({
      time: this.getCurrentTime(),
      isSpontaneous: isSpontaneous,
      userMessage: currentMessage.text,
      replyContext: replyContext,
      history: contextStr,
      personalInfo: personalInfo,
      senderName: currentMessage.sender,
      chatContext: chatProfile
  });

  // 3. –ó–ê–ü–†–û–° –ö SMART –ú–û–î–ï–õ–ò (API)
  if (this.openai) {
      try {
          const messages = [{ role: "system", content: prompts.system() }, { role: "user", content: [] }];
          messages[1].content.push({ type: "text", text: fullPromptText });
          if (imageBuffer) {
              messages[1].content.push({
                  type: "image_url",
                  image_url: { url: `data:${mimeType};base64,${imageBuffer.toString('base64')}` }
              });
          }

          const completion = await this.openai.chat.completions.create({
              model: config.mainModel,
              messages: messages,
              max_tokens: 2500,
              temperature: 0.9,
          });
          
          this.stats.smart++; 
          return completion.choices[0].message.content.replace(/^thought[\s\S]*?\n\n/i, ''); 
      } catch (e) {
          console.error(`[API SMART FAIL] ${e.message}. Fallback to Native...`);
      }
  }

  // 4. FALLBACK (–ï—Å–ª–∏ API —É–ø–∞–ª –∏–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç)
  return this.generateViaNative(history, currentMessage, imageBuffer, mimeType, userInstruction, userProfile, isSpontaneous, chatProfile);
}

// Helper –¥–ª—è Native –≤—ã–∑–æ–≤–∞ (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥)
async generateViaNative(history, currentMessage, imageBuffer, mimeType, userInstruction, userProfile, isSpontaneous, chatProfile = null) {
    const relevantHistory = history.slice(-20);
    const contextStr = relevantHistory.map(m => `${m.role}: ${m.text}`).join('\n');

    // –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–∫–∞–∫ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ—Ç–æ–¥–µ)
    let personalInfo = "";
    let replyContext = "";

    if (currentMessage.replyText) {
        replyContext = `!!! –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨ –û–¢–í–ï–¢–ò–õ –ù–ê –°–û–û–ë–©–ï–ù–ò–ï:\n"${currentMessage.replyText}"`;
    }

    if (userInstruction) {
        personalInfo += `\n!!! –°–ü–ï–¶-–ò–ù–°–¢–†–£–ö–¶–ò–Ø !!!\n${userInstruction}\n`;
    }

    if (userProfile) {
        const score = userProfile.relationship || 50;
        let relationText = score <= 20 ? "–°–¢–ê–¢–£–°: –í–†–ê–ì." : score >= 80 ? "–°–¢–ê–¢–£–°: –ë–†–ê–¢–ê–ù." : "–°–¢–ê–¢–£–°: –ù–ï–ô–¢–†–ê–õ–¨–ù–û.";
        personalInfo += `\n--- –î–û–°–¨–ï ---\n–§–∞–∫—Ç—ã: ${userProfile.facts || "–ù–µ—Ç"}\n`;
        if (userProfile.location) personalInfo += `üìç –õ–æ–∫–∞—Ü–∏—è: ${userProfile.location}\n`;
        personalInfo += `${relationText}\n-----------------\n`;
    }

    const fullPromptText = prompts.mainChat({
        time: this.getCurrentTime(),
        isSpontaneous: isSpontaneous,
        userMessage: currentMessage.text,
        replyContext: replyContext,
        history: contextStr,
        personalInfo: personalInfo,
        senderName: currentMessage.sender,
        chatContext: chatProfile
    });

    return this.executeNativeWithRetry(async () => {
      let promptParts = [];
      if (imageBuffer) promptParts.push({ inlineData: { mimeType: mimeType, data: imageBuffer.toString("base64") } });
      promptParts.push({ text: fullPromptText });

      const result = await this.nativeModel.generateContent({
          contents: [{ role: 'user', parts: promptParts }],
          generationConfig: { maxOutputTokens: 2500, temperature: 0.9 }
      });
      
      let text = result.response.text();
      if (result.response.candidates[0].groundingMetadata?.groundingChunks) {
           const links = result.response.candidates[0].groundingMetadata.groundingChunks
              .filter(c => c.web?.uri).map(c => `[${c.web.title || "–ò—Å—Ç–æ—á–Ω–∏–∫"}](${c.web.uri})`);
           const unique = [...new Set(links)].slice(0, 3);
           if (unique.length > 0) text += "\n\n–ù–∞—à–µ–ª —Ç—É—Ç: " + unique.join(" ‚Ä¢ ");
      }
      return text;
    });
}

// === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ (LOGIC MODEL) ===
  
  // –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ª–æ–≥–∏–∫–∏
  async runLogicModel(promptJson) {
    // 1. –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ API (Logic Model)
    if (this.openai) {
        try {
            const completion = await this.openai.chat.completions.create({
                model: config.logicModel,
                messages: [{ role: "user", content: promptJson }],
                response_format: { type: "json_object" }
            });
            this.stats.logic++;
            return JSON.parse(completion.choices[0].message.content);
        } catch (e) {}
    }
    // 2. Fallback Native
    try {
        return await this.executeNativeWithRetry(async () => {
           const result = await this.nativeModel.generateContent(promptJson);
           let text = result.response.text().replace(/```json/g, '').replace(/```/g, '').trim();
           const first = text.indexOf('{'), last = text.lastIndexOf('}');
           if (first !== -1 && last !== -1) text = text.substring(first, last + 1);
           return JSON.parse(text);
        });
    } catch (e) { return null; }
}

// –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç (–¥–ª—è —Ä–µ–∞–∫—Ü–∏–π –∏ ShouldAnswer)
async runLogicText(promptText) {
    if (this.openai) {
        try {
          const completion = await this.openai.chat.completions.create({
              model: config.logicModel,
              messages: [{ role: "user", content: promptText }]
          });
          this.stats.logic++;
          return completion.choices[0].message.content;
        } catch (e) {}
    }
    return null; 
}

async analyzeUserImmediate(lastMessages, currentProfile) {
    return this.runLogicModel(prompts.analyzeImmediate(currentProfile, lastMessages));
}

// –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ (AI-—Ä–µ—à–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ regex)
async checkSearchNeeded(userMessage, recentHistory, chatTopic) {
    const prompt = prompts.shouldSearch(
        this.getCurrentTime(),
        userMessage,
        recentHistory,
        chatTopic
    );

    try {
        const result = await this.runLogicModel(prompt);
        if (result && typeof result.needsSearch === 'boolean') {
            console.log(`[SEARCH CHECK] needsSearch=${result.needsSearch}, query="${result.searchQuery}", reason="${result.reason}"`);
            return result;
        }
    } catch (e) {
        console.error(`[SEARCH CHECK ERROR] ${e.message}`);
    }

    // Fallback: –Ω–µ –∏—Å–∫–∞—Ç—å –µ—Å–ª–∏ AI –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª
    return { needsSearch: false, searchQuery: null, reason: "fallback" };
}

async analyzeBatch(messagesBatch, currentProfiles) {
    const chatLog = messagesBatch.map(m => `[ID:${m.userId}] ${m.name}: ${m.text}`).join('\n');
    const knownInfo = Object.entries(currentProfiles).map(([uid, p]) => `ID:${uid} -> ${p.realName}, ${p.facts}, ${p.attitude}`).join('\n');
    return this.runLogicModel(prompts.analyzeBatch(knownInfo, chatLog));
}

// –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ñ–∏–ª—è —á–∞—Ç–∞ (–∫–∞–∂–¥—ã–µ 50 —Å–æ–æ–±—â–µ–Ω–∏–π)
async analyzeChatProfile(messagesBatch, currentProfile) {
    const messagesText = messagesBatch.map(m => `${m.name}: ${m.text}`).join('\n');
    return this.runLogicModel(prompts.analyzeChatProfile(currentProfile, messagesText));
}

async determineReaction(contextText) {
  const allowed = ["üëç", "üëé", "‚ù§", "üî•", "ü•∞", "üëè", "üòÅ", "ü§î", "ü§Ø", "üò±", "ü§¨", "üò¢", "üéâ", "ü§©", "ü§Æ", "üí©", "üôè", "üëå", "üïä", "ü§°", "ü•±", "ü•¥", "üòç", "üê≥", "‚ù§‚Äçüî•", "üåö", "üå≠", "üíØ", "ü§£", "‚ö°", "üçå", "üèÜ", "üíî", "ü§®", "üòê", "üçì", "üçæ", "üíã", "üñï", "üòà", "üò¥", "üò≠", "ü§ì", "üëª", "üë®‚Äçüíª", "üëÄ", "üéÉ", "üôà", "üòá", "üò®", "ü§ù", "‚úç", "ü§ó", "ü´°", "üéÖ", "üéÑ", "‚òÉ", "üíÖ", "ü§™", "üóø", "üÜí", "üíò", "üôâ", "ü¶Ñ", "üòò", "üíä", "üôä", "üòé", "üëæ", "ü§∑‚Äç‚ôÇ", "ü§∑", "ü§∑‚Äç‚ôÄ", "üò°"];
  const text = await this.runLogicText(prompts.reaction(contextText, allowed.join(" ")));
  if (!text) return null;
  const match = text.match(/(\p{Emoji_Presentation}|\p{Extended_Pictographic})/u);
  return (match && allowed.includes(match[0])) ? match[0] : null;
}

async generateProfileDescription(profileData, targetName) {
    if (this.openai) {
      try {
          const completion = await this.openai.chat.completions.create({ model: config.mainModel, messages: [{ role: "user", content: prompts.profileDescription(targetName, profileData) }] });
          this.stats.smart++; return completion.choices[0].message.content;
      } catch(e) {}
    }
    return "–ù–µ –∑–Ω–∞—é —Ç–∞–∫–æ–≥–æ.";
}

async generateFlavorText(task, result) {
  if (this.openai) {
      try {
          const completion = await this.openai.chat.completions.create({ model: config.mainModel, messages: [{ role: "user", content: prompts.flavor(task, result) }] });
          this.stats.smart++; return completion.choices[0].message.content.trim().replace(/^["']|["']$/g, '');
      } catch(e) {}
  }
  return `${result}`;
}

  // === –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø ===
  async transcribeAudio(audioBuffer, userName, mimeType) {
    // –¢–æ–ª—å–∫–æ Native –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–æ–≤ –∏–∑ –±—É—Ñ–µ—Ä–∞ —Ç–∞–∫ –ª–µ–≥–∫–æ –∏ –±–µ—Å–ø–ª–∞—Ç–Ω–æ
    if (!this.keys || this.keys.length === 0) {
        console.warn("[AI WARN] –ü–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ, –Ω–æ –Ω–µ—Ç –∫–ª—é—á–µ–π Google –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏. –ü—Ä–æ–ø—É—Å–∫–∞—é.");
        return null;
    }

    try {
        return await this.executeNativeWithRetry(async () => {
          const parts = [ { inlineData: { mimeType: mimeType, data: audioBuffer.toString("base64") } }, { text: prompts.transcription(userName) }];
          const result = await this.nativeModel.generateContent(parts);
          let text = result.response.text().replace(/```json/g, '').replace(/```/g, '').trim();
          const first = text.indexOf('{'), last = text.lastIndexOf('}');
          if (first !== -1 && last !== -1) text = text.substring(first, last + 1);
          return JSON.parse(text);
        });
    } catch (e) { 
        console.error(`[TRANSCRIPTION FAIL] ${e.message}`);
        return null; 
    }
  }

  // === –ü–ê–†–°–ò–ù–ì –ù–ê–ü–û–ú–ò–ù–ê–ù–ò–Ø (–° –ö–û–ù–¢–ï–ö–°–¢–û–ú) ===
  async parseReminder(userText, contextText = "") {
    const now = this.getCurrentTime();
    const prompt = prompts.parseReminder(now, userText, contextText);
    return this.runLogicModel(prompt);
  }
}

module.exports = new AiService();